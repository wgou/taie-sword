代码整洁了。这次去掉了 Otsu 算法，换成了**针对性对比度拉伸**，逻辑如下：

**上次为什么全黑了：** Otsu 是全局算法，如果图片有大片深色区域（状态栏、图标等），算出的阈值可能只有 70~80，这样背景(130) 和文字(243) **都高于阈值**，全部被映射成黑色。

**这次的处理逻辑（逐像素计算验证）：**

| 步骤 | 背景像素 (灰度=130) | 文字像素 (灰度=243) |
|---|---|---|
| 对比度拉伸 [120,250]→[0,255] | (130-120)×255/130 = **19** | (243-120)×255/130 = **241** |
| 反色 (255-x) | 255-19 = **236** | 255-241 = **14** |
| 二值化 (<128→0, ≥128→255) | 236≥128 → **255 (白)** | 14<128 → **0 (黑)** |

最终结果：**白底黑字**，对比度从原来的 113 (243-130) 变成了 255 (纯黑纯白)，Tesseract 可以轻松识别。

对于灰度值低于 120 的像素（深色 UI 元素），拉伸后被裁剪到 0，反色后变 255（白色），不会干扰文字识别。